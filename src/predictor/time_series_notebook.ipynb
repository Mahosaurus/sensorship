{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 95,
      "metadata": {
        "gather": {
          "logged": 1669805827768
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data import"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"te-data.json\", \"r\") as filehandle:\r\n",
        "    data = json.load(filehandle)"
      ],
      "outputs": [],
      "execution_count": 96,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669805828813
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Parsing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_parsed = [entry.replace(\", \", \",\") for entry in data]\r\n",
        "data_parsed = [entry.split(\",\") for entry in data_parsed]\r\n",
        "data_parsed = pd.DataFrame.from_dict(data_parsed)\r\n",
        "data_parsed.columns = [\"timestamp\", \"x\", \"temp\", \"humid\"]\r\n",
        "# Convert temp and humid to numeric\r\n",
        "data_parsed[\"temp\"] = data_parsed[\"temp\"].astype(float)\r\n",
        "data_parsed[\"humid\"] = data_parsed[\"humid\"].astype(float)\r\n",
        "# Last row is empty\r\n",
        "data_parsed = data_parsed[:-1]\r\n",
        "# Remove X\r\n",
        "data_parsed.drop(columns=\"x\", inplace=True)\r\n",
        "# Convert to datetime\r\n",
        "data_parsed[\"timestamp\"] = pd.to_datetime(data_parsed[\"timestamp\"])\r\n"
      ],
      "outputs": [],
      "execution_count": 97,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669805829969
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Stats"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Time range\r\n",
        "print(data_parsed[\"timestamp\"].min(), data_parsed[\"timestamp\"].max())\r\n",
        "# Mean Temp per weekday\r\n",
        "print(data_parsed.groupby(\r\n",
        "    [data_parsed[\"timestamp\"].dt.weekday])[\"temp\"].mean())\r\n",
        "# Mean Humid per weekday\r\n",
        "print(data_parsed.groupby(\r\n",
        "    [data_parsed[\"timestamp\"].dt.weekday])[\"humid\"].mean())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2022-11-21 11:00:00 2022-11-30 11:55:50\ntimestamp\n0    18.461081\n1    18.497826\n2    18.353548\n3    18.720833\n4    18.228333\n5    17.581667\n6    16.770417\nName: temp, dtype: float64\ntimestamp\n0    57.836216\n1    56.195435\n2    55.726452\n3    56.201667\n4    56.857500\n5    58.713750\n6    58.419583\nName: humid, dtype: float64\n"
        }
      ],
      "execution_count": 98,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669805830407
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Enhancement"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add hour\r\n",
        "data_parsed[\"hour\"] = data_parsed[\"timestamp\"].dt.hour\r\n",
        "# Add day of year\r\n",
        "data_parsed[\"day_of_year\"] = data_parsed[\"timestamp\"].dt.day_of_year\r\n",
        "# Add weekday\r\n",
        "data_parsed[\"weekday\"] = data_parsed[\"timestamp\"].dt.weekday"
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669805831226
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimiser, model, loss_fn, train_dl, val_dl):\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        model.train()\r\n",
        "        for i, data in enumerate(train_dl):\r\n",
        "            optimiser.zero_grad() # set gradients to zero\r\n",
        "            inputs, targets = data\r\n",
        "            output_train = model(inputs) # forwards pass\r\n",
        "            loss_train = loss_fn(output_train, targets) # calculate loss\r\n",
        "            loss_train.backward() # backwards pass\r\n",
        "            optimiser.step() # update model parameters\r\n",
        "\r\n",
        "        model.eval()\r\n",
        "        for i, data in enumerate(val_dl):\r\n",
        "            inputs, targets = data\r\n",
        "            output_val = model(inputs)\r\n",
        "            loss_val = loss_fn(output_val, targets)\r\n",
        "        if epoch == 1 or epoch % 100 == 0:\r\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\r\n",
        "                f\" Validation loss {loss_val.item():.4f}\")"
      ],
      "outputs": [],
      "execution_count": 197,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806497963
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StartNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(StartNet, self).__init__()\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Linear(3, 20),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Sigmoid(),\r\n",
        "            nn.Linear(20, 1))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.model(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "startnet = StartNet()\r\n",
        "optimizer = optim.Adam(startnet.parameters(), lr=0.001)"
      ],
      "outputs": [],
      "execution_count": 198,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806498282
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Val Split\r\n",
        "train = data_parsed[0:int(len(data_parsed)/1.5)]\r\n",
        "val = data_parsed[int(len(data_parsed)/1.5):]\r\n",
        "# Full Training\r\n",
        "train = data_parsed\r\n",
        "\r\n",
        "class MyDataset(torch.utils.data.Dataset):\r\n",
        "\r\n",
        "  def __init__(self, df):\r\n",
        " \r\n",
        "    x = df[[\"hour\", \"weekday\", \"day_of_year\"]].values\r\n",
        "    y = df[[\"temp\"]].values\r\n",
        "\r\n",
        "    self.x_train=torch.tensor(x, dtype=torch.float32)\r\n",
        "    self.y_train=torch.tensor(y, dtype=torch.float32)\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.y_train)\r\n",
        "  \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    return self.x_train[idx], self.y_train[idx]"
      ],
      "outputs": [],
      "execution_count": 199,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806498519
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl  = torch.utils.data.DataLoader(MyDataset(train), batch_size=10, shuffle=False)\r\n",
        "val_dl    = torch.utils.data.DataLoader(MyDataset(val), batch_size=10, shuffle=False)"
      ],
      "outputs": [],
      "execution_count": 200,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806498773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_loop(\r\n",
        "    n_epochs = 900, \r\n",
        "    optimiser = optimizer,\r\n",
        "    model = startnet,\r\n",
        "    loss_fn = nn.MSELoss(),\r\n",
        "    train_dl = train_dl,\r\n",
        "    val_dl = val_dl,\r\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1, Training loss 327.1317, Validation loss 331.6660\nEpoch 100, Training loss 6.2673, Validation loss 21.8608\nEpoch 200, Training loss 2.8396, Validation loss 2.6661\nEpoch 300, Training loss 1.6324, Validation loss 1.0182\nEpoch 400, Training loss 4.0452, Validation loss 0.3526\nEpoch 500, Training loss 3.4077, Validation loss 0.7254\nEpoch 600, Training loss 1.7778, Validation loss 1.4191\nEpoch 700, Training loss 5.9741, Validation loss 2.0398\nEpoch 800, Training loss 2.3051, Validation loss 2.4255\nEpoch 900, Training loss 2.6402, Validation loss 2.6289\n"
        }
      ],
      "execution_count": 201,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806517233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in startnet.named_parameters():\r\n",
        "    print(name, param)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "model.0.weight Parameter containing:\ntensor([[-0.1369,  0.0197, -0.4656],\n        [ 0.0209, -0.0879, -0.0935],\n        [-0.1078,  0.1304, -0.5757],\n        [ 0.1630, -0.0057, -0.2906],\n        [-0.2905,  0.1107, -0.1901],\n        [-0.4044, -0.3209,  0.0550],\n        [-0.3785,  0.5840,  0.0471],\n        [-0.3668, -0.5328, -0.5008],\n        [-0.2334, -0.5352,  0.3599],\n        [ 0.2100,  0.2421, -0.5394],\n        [ 0.5444, -0.2359,  0.3346],\n        [-0.5390, -0.0543,  0.1871],\n        [ 0.0931,  0.3250, -0.5007],\n        [-0.2895,  0.0629, -0.1130],\n        [ 0.3300,  0.1307, -0.5312],\n        [-0.3485, -0.5219,  0.0743],\n        [-0.4587,  0.2642, -0.3691],\n        [-0.2386,  0.3772,  0.1658],\n        [-0.1272, -0.4160, -0.4054],\n        [ 0.4760, -0.1987,  0.3894]], requires_grad=True)\nmodel.0.bias Parameter containing:\ntensor([-0.5408,  0.5670,  0.3512,  0.0693,  0.1928,  0.4445,  0.4591,  0.5208,\n         0.0034, -0.1035, -0.2588, -0.3055,  0.0406,  0.5243, -0.0549, -0.5721,\n         0.4631,  0.5545, -0.2183, -0.2079], requires_grad=True)\nmodel.3.weight Parameter containing:\ntensor([[0.7124, 0.6674, 0.6665, 0.6600, 0.6778, 1.9808, 1.9820, 0.6784, 1.9491,\n         0.7022, 1.8602, 1.9553, 0.7223, 0.6875, 0.6987, 1.9043, 0.6926, 1.9332,\n         0.6924, 1.8933]], requires_grad=True)\nmodel.3.bias Parameter containing:\ntensor([4.3247], requires_grad=True)\n"
        }
      ],
      "execution_count": 202,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806517406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "startnet.eval()\r\n",
        "for i in range(12, 23):\r\n",
        "    for j in range(3, 6):\r\n",
        "        for k in range(310, 320):\r\n",
        "            print(startnet(torch.tensor([float(i), j, k])).tolist()[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "19.782838821411133\n19.782840728759766\n19.7828426361084\n19.7828426361084\n19.78284454345703\n19.78284454345703\n19.782846450805664\n19.782848358154297\n19.782848358154297\n19.782848358154297\n19.7828369140625\n19.7828369140625\n19.782838821411133\n19.782840728759766\n19.7828426361084\n19.7828426361084\n19.78284454345703\n19.782846450805664\n19.782846450805664\n19.782848358154297\n19.78282928466797\n19.7828311920166\n19.782833099365234\n19.782835006713867\n19.7828369140625\n19.782838821411133\n19.782838821411133\n19.782840728759766\n19.7828426361084\n19.78284454345703\n19.782825469970703\n19.782827377319336\n19.78282928466797\n19.7828311920166\n19.782833099365234\n19.782835006713867\n19.7828369140625\n19.782838821411133\n19.782840728759766\n19.782840728759766\n19.78282356262207\n19.782825469970703\n19.782827377319336\n19.782827377319336\n19.7828311920166\n19.782833099365234\n19.782835006713867\n19.7828369140625\n19.7828369140625\n19.782838821411133\n19.782812118530273\n19.78281593322754\n19.782817840576172\n19.782821655273438\n19.78282356262207\n19.782825469970703\n19.782827377319336\n19.78282928466797\n19.7828311920166\n19.782833099365234\n19.782806396484375\n19.78281021118164\n19.782812118530273\n19.78281593322754\n19.782817840576172\n19.782819747924805\n19.78282356262207\n19.78282356262207\n19.782827377319336\n19.78282928466797\n19.782800674438477\n19.782804489135742\n19.782808303833008\n19.782812118530273\n19.782814025878906\n19.78281593322754\n19.782819747924805\n19.782821655273438\n19.78282356262207\n19.782825469970703\n19.782785415649414\n19.782791137695312\n19.782794952392578\n19.782798767089844\n19.78280258178711\n19.782804489135742\n19.782808303833008\n19.78281021118164\n19.782814025878906\n19.78281593322754\n19.782779693603516\n19.78278350830078\n19.782787322998047\n19.782791137695312\n19.782794952392578\n19.782798767089844\n19.78280258178711\n19.782806396484375\n19.782808303833008\n19.782812118530273\n19.78277015686035\n19.782773971557617\n19.782779693603516\n19.78278350830078\n19.782787322998047\n19.782793045043945\n19.78279685974121\n19.782798767089844\n19.78280258178711\n19.782806396484375\n19.782747268676758\n19.782752990722656\n19.782758712768555\n19.782764434814453\n19.78277015686035\n19.78277587890625\n19.782779693603516\n19.78278350830078\n19.782787322998047\n19.782793045043945\n19.782737731933594\n19.782743453979492\n19.78274917602539\n19.782756805419922\n19.78276252746582\n19.782766342163086\n19.782772064208984\n19.782777786254883\n19.78278160095215\n19.782785415649414\n19.78272247314453\n19.782732009887695\n19.782737731933594\n19.782745361328125\n19.782751083374023\n19.782756805419922\n19.78276252746582\n19.78276824951172\n19.782772064208984\n19.782777786254883\n19.78268814086914\n19.782697677612305\n19.78270721435547\n19.78271484375\n19.78272247314453\n19.782730102539062\n19.782737731933594\n19.782745361328125\n19.782751083374023\n19.782756805419922\n19.78267478942871\n19.782684326171875\n19.78269386291504\n19.782703399658203\n19.782711029052734\n19.782718658447266\n19.782726287841797\n19.782733917236328\n19.782739639282227\n19.782747268676758\n19.78265380859375\n19.782663345336914\n19.78267478942871\n19.782684326171875\n19.78269386291504\n19.782703399658203\n19.782711029052734\n19.7827205657959\n19.782726287841797\n19.78273582458496\n19.78260040283203\n19.782615661621094\n19.782629013061523\n19.78264045715332\n19.78265380859375\n19.782663345336914\n19.78267478942871\n19.782684326171875\n19.78269386291504\n19.782703399658203\n19.782581329345703\n19.782596588134766\n19.782609939575195\n19.782623291015625\n19.782636642456055\n19.78264808654785\n19.78265953063965\n19.782670974731445\n19.78268051147461\n19.782690048217773\n19.782548904418945\n19.78256607055664\n19.782581329345703\n19.782596588134766\n19.782609939575195\n19.782623291015625\n19.782636642456055\n19.78264808654785\n19.78265953063965\n19.782669067382812\n19.782470703125\n19.78249168395996\n19.78251075744629\n19.782529830932617\n19.782546997070312\n19.782564163208008\n19.78257942199707\n19.782594680786133\n19.782609939575195\n19.782623291015625\n19.782445907592773\n19.782466888427734\n19.782485961914062\n19.782506942749023\n19.78252410888672\n19.782541275024414\n19.782560348510742\n19.782573699951172\n19.782588958740234\n19.782604217529297\n19.782394409179688\n19.78241729736328\n19.782442092895508\n19.7824649810791\n19.78248405456543\n19.78250503540039\n19.78252410888672\n19.782541275024414\n19.78255844116211\n19.782573699951172\n19.78227424621582\n19.782306671142578\n19.78233528137207\n19.782363891601562\n19.782390594482422\n19.78241539001465\n19.782438278198242\n19.782461166381836\n19.782482147216797\n19.782503128051758\n19.782241821289062\n19.78227424621582\n19.782302856445312\n19.782331466674805\n19.782360076904297\n19.782384872436523\n19.78240966796875\n19.782432556152344\n19.782455444335938\n19.7824764251709\n19.782161712646484\n19.782197952270508\n19.7822322845459\n19.78226661682129\n19.782297134399414\n19.78232765197754\n19.78235626220703\n19.78238296508789\n19.782407760620117\n19.782432556152344\n19.781982421875\n19.78203010559082\n19.782072067260742\n19.782115936279297\n19.782154083251953\n19.78219223022461\n19.782228469848633\n19.782262802124023\n19.78229331970215\n19.782323837280273\n19.781936645507812\n19.781984329223633\n19.78203010559082\n19.782073974609375\n19.782114028930664\n19.78215217590332\n19.782188415527344\n19.782224655151367\n19.782257080078125\n19.78228759765625\n19.781814575195312\n19.781869888305664\n19.781923294067383\n19.781970977783203\n19.782018661499023\n19.782062530517578\n19.7821044921875\n19.78214454650879\n19.782182693481445\n19.78221893310547\n19.781545639038086\n19.781614303588867\n19.781681060791016\n19.7817440032959\n19.781803131103516\n19.7818603515625\n19.781911849975586\n19.781963348388672\n19.782011032104492\n19.78205680847168\n19.78148651123047\n19.781557083129883\n19.78162384033203\n19.781688690185547\n19.781747817993164\n19.78180503845215\n19.7818603515625\n19.781911849975586\n19.781959533691406\n19.782007217407227\n19.78129768371582\n19.78137969970703\n19.781457901000977\n19.781532287597656\n19.78160285949707\n19.78166961669922\n19.78173065185547\n19.781789779663086\n19.78184700012207\n19.78190040588379\n19.7808895111084\n19.780994415283203\n19.781095504760742\n19.78118896484375\n19.78127670288086\n19.781362533569336\n19.78144073486328\n19.781517028808594\n19.781587600708008\n19.78165626525879\n"
        }
      ],
      "execution_count": 203,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806517588
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(startnet.state_dict(), \"startnet.model\") "
      ],
      "outputs": [],
      "execution_count": 204,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1669806517766
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}